{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-03-26T05:40:11.673186Z",
     "iopub.execute_input": "2023-03-26T05:40:11.673598Z",
     "iopub.status.idle": "2023-03-26T05:40:11.722229Z",
     "shell.execute_reply.started": "2023-03-26T05:40:11.673565Z",
     "shell.execute_reply": "2023-03-26T05:40:11.720990Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/lib/kaggle/gcp.py\n/kaggle/input/custom/test_data_nomentions_sanitized.csv\n/kaggle/input/custom/train_data_noemoji_nomentions.csv\n/kaggle/input/nitro-language-processing-2/sample_submission.csv\n/kaggle/input/nitro-language-processing-2/random_seed_setter.py\n/kaggle/input/nitro-language-processing-2/train_data.csv\n/kaggle/input/nitro-language-processing-2/test_data.csv\n/kaggle/input/nitro-language-processing-2/random_seeds.csv\n/kaggle/working/__notebook_source__.ipynb\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset\n",
    "import wandb\n",
    "import shutil\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import os\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-26T05:40:11.724169Z",
     "iopub.execute_input": "2023-03-26T05:40:11.726643Z",
     "iopub.status.idle": "2023-03-26T05:40:25.592549Z",
     "shell.execute_reply.started": "2023-03-26T05:40:11.726606Z",
     "shell.execute_reply": "2023-03-26T05:40:25.591346Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SexismDetectionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes,\n",
    "                                                                        return_dict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bert_model(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-26T05:40:25.594319Z",
     "iopub.execute_input": "2023-03-26T05:40:25.594746Z",
     "iopub.status.idle": "2023-03-26T05:40:25.601714Z",
     "shell.execute_reply.started": "2023-03-26T05:40:25.594703Z",
     "shell.execute_reply": "2023-03-26T05:40:25.600486Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SexismDataset(Dataset):\n",
    "\n",
    "    def __init__(self, model_name,  file, test=False):\n",
    "        data = pd.read_csv(file)\n",
    "        self.text = data[\"Text\"].tolist()\n",
    "        self.label_mapping = {\n",
    "            'direct': 0,\n",
    "            'descriptive': 1,\n",
    "            'reporting': 2,\n",
    "            'offensive': 3,\n",
    "            'non-offensive': 4\n",
    "        }\n",
    "        self.padding = 64\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.test = test\n",
    "        self.maximum = 0\n",
    "        self.count = 0\n",
    "        if not test:\n",
    "            self.labels = data[\"Final Labels\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "         \n",
    "        input_ids = self.tokenizer.encode(self.text[item], add_special_tokens=True, return_tensors=\"pt\",\n",
    "                                          max_length=self.padding,\n",
    "                                          padding='max_length',\n",
    "                                          truncation=True).view(-1)\n",
    "        if not self.test:\n",
    "            return input_ids, self.label_mapping[self.labels[item]]\n",
    "        return input_ids"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-26T05:40:25.604509Z",
     "iopub.execute_input": "2023-03-26T05:40:25.605212Z",
     "iopub.status.idle": "2023-03-26T05:40:25.616487Z",
     "shell.execute_reply.started": "2023-03-26T05:40:25.605177Z",
     "shell.execute_reply": "2023-03-26T05:40:25.615454Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def save_ckp(state, is_best, checkpoint_dir, best_model_dir):\n",
    "    f_path = checkpoint_dir + '/checkpoint.pt'\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir + '/best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['best_acc']\n",
    "\n",
    "\n",
    "def get_weighted_sampler(dataset):\n",
    "    class_indices = {}\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        if label not in class_indices:\n",
    "            class_indices[label] = []\n",
    "        class_indices[label].append(i)\n",
    "\n",
    "    class_weights = {}\n",
    "    for label in class_indices:\n",
    "        class_weights[label] = 1 / len(class_indices[label])\n",
    "\n",
    "    weights = [class_weights[label] for _, label in dataset]\n",
    "    oversample_sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "    return oversample_sampler\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "\n",
    "    def __init__(self, device, model, criterion, optimizer, dataset, validation_split=.2,\n",
    "                 batch_size=32, shuffle_dataset=True,\n",
    "                 random_seed=42, resume_from_checkpoint=False, project_name=\"Training\", architecture=\"Unknown\",\n",
    "                 num_epochs=25, initial_lr=None, num_classes=None, weighted_sampler=False):\n",
    "\n",
    "        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "        os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "        if resume_from_checkpoint:\n",
    "            self.model, self.optimizer, self.start_epoch, self.best_acc = load_ckp(\n",
    "                'checkpoint/checkpoint.pt',\n",
    "                model, optimizer)\n",
    "        else:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.start_epoch = 0\n",
    "            self.best_acc = 0.0\n",
    "\n",
    "        self.model.to(device)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.shuffle_dataset = shuffle_dataset\n",
    "        self.random_seed = random_seed\n",
    "        self.dataset_size = len(dataset)\n",
    "        self.validation_split = validation_split\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.lr_scheduler = None\n",
    "        self.epochs = num_epochs\n",
    "        self.nr_batch_report = 5\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        test_size = int(self.validation_split * len(dataset))\n",
    "        train_size = len(dataset) - test_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        if not weighted_sampler:\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                                       num_workers=0, drop_last=True)\n",
    "        else:\n",
    "            weighted_sampler = get_weighted_sampler(train_dataset)\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                                       sampler=weighted_sampler,\n",
    "                                                       num_workers=0, drop_last=True)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                                  num_workers=0, drop_last=True)\n",
    "\n",
    "        self.dataloaders = {'train': train_loader,\n",
    "                            'val': test_loader}\n",
    "\n",
    "        self.dataset_sizes = {\"train\": train_size, \"val\": test_size}\n",
    "\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "        # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=project_name,\n",
    "\n",
    "            # track hyper parameters and run metadata\n",
    "            config={\n",
    "                \"architecture\": architecture,\n",
    "                \"epochs\": num_epochs,\n",
    "                \"nr_batch_report\": self.nr_batch_report,\n",
    "                \"initial_lr\": initial_lr if initial_lr else \"Unknown\",\n",
    "                \"batch_size\": self.batch_size\n",
    "            }\n",
    "        )\n",
    "\n",
    "        wandb.log({\"train_size\": train_size, \"test_size\": test_size})\n",
    "\n",
    "    def set_lr_scheduler(self, scheduler):\n",
    "        self.lr_scheduler = scheduler\n",
    "\n",
    "    def train_model(self):\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "            # Each epoch has a training and validation phase\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch\n",
    "            })\n",
    "            for phase in ['train', 'val']:\n",
    "                torch.cuda.empty_cache()\n",
    "                if phase == 'train':\n",
    "                    self.model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    self.model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                for batch_idx, (inputs, labels) in enumerate(self.dataloaders[phase]):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = torch.as_tensor(labels).to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = self.model(inputs)\n",
    "                        if type(outputs) is tuple:\n",
    "                            outputs = outputs[0]\n",
    "                        loss = self.criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                        if batch_idx % self.nr_batch_report == 0:\n",
    "                            wandb.log({\"loss\": loss.item()})\n",
    "                            if self.lr_scheduler:\n",
    "                                wandb.log({\"lr\": self.lr_scheduler.get_last_lr()[-1]})\n",
    "                                self.lr_scheduler.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    y_pred.extend(preds.tolist())\n",
    "                    y_true.extend(labels.tolist())\n",
    "\n",
    "                epoch_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "                if phase == 'val':\n",
    "                    wandb.log({\n",
    "                        \"epoch_acc_val\": epoch_acc,\n",
    "                    })\n",
    "                else:\n",
    "                    epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                    wandb.log({\n",
    "                        \"epoch_acc_train\": epoch_acc,\n",
    "                        \"epoch_loss_train\": epoch_loss,\n",
    "                    })\n",
    "\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                    'best_acc': self.best_acc\n",
    "                }\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > self.best_acc:\n",
    "                    save_ckp(checkpoint, True, \"checkpoint\", 'best_model')\n",
    "                    self.best_acc = epoch_acc\n",
    "                    wandb.log({\n",
    "                        \"best_acc_val\": self.best_acc\n",
    "                    })\n",
    "                save_ckp(checkpoint, False, \"checkpoint\", 'best_model')\n",
    "        return self.model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-26T05:40:25.618359Z",
     "iopub.execute_input": "2023-03-26T05:40:25.619057Z",
     "iopub.status.idle": "2023-03-26T05:40:25.901737Z",
     "shell.execute_reply.started": "2023-03-26T05:40:25.619023Z",
     "shell.execute_reply": "2023-03-26T05:40:25.900669Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "torch.manual_seed(123)\n",
    "model_name = \"dumitrescustefan/bert-base-romanian-uncased-v1\"\n",
    "dataset = SexismDataset(model_name, \"dataset/train_data_final.csv\")\n",
    "model = SexismDetectionModel(model_name, num_classes=5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "if not os.path.exists(\"best_model\"):\n",
    "    os.makedirs(\"best_model\")\n",
    "    \n",
    "if not os.path.exists(\"checkpoint\"):\n",
    "    os.makedirs(\"checkpoint\")\n",
    "\n",
    "# if the program was interrupted we will resume from the last saved model\n",
    "print('Type 0 to exit, 1 to start fresh, 2 from checkpoint')\n",
    "inp = input()\n",
    "if inp == '0':\n",
    "    exit(0)\n",
    "\n",
    "trainer = ModelTrainer(device, model, criterion, optimizer, dataset,\n",
    "                        resume_from_checkpoint=(inp == '2'), project_name=\"Sexism NLP Hackathon\",\n",
    "                        architecture=\"Bert-Romanian SD\", num_epochs=200, batch_size=256, initial_lr=1e-5,\n",
    "                        validation_split=0.1,\n",
    "                        num_classes=5, weighted_sampler=True)\n",
    "trainer.train_model()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-26T05:40:25.903498Z",
     "iopub.execute_input": "2023-03-26T05:40:25.903871Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"dumitrescustefan/bert-base-romanian-uncased-v1\"\n",
    "model = SexismDetectionModel(model_name, num_classes=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "model, optimizer, last_epoch, acc = load_ckp('best_model/best_model.pt', model, optimizer)\n",
    "dataset = SexismDataset(model_name, 'dataset/test_data_final.csv', test=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "to_label = {\n",
    "    0: 'direct',\n",
    "    1: 'descriptive',\n",
    "    2: 'reporting',\n",
    "    3: 'offensive',\n",
    "    4: 'non-offensive'\n",
    "}\n",
    "\n",
    "predictions = []\n",
    "ids = [i for i in range(len(dataset))]\n",
    "with torch.no_grad():\n",
    "    for inp in dataloader:\n",
    "        inp = inp.to(device)\n",
    "        outputs = model(inp)\n",
    "        if type(outputs) is tuple:\n",
    "            outputs = outputs[0]\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.tolist())\n",
    "\n",
    "\n",
    "pred = [to_label[pr] for pr in predictions]\n",
    "output = pd.DataFrame({'Id': ids, 'Label': pred})\n",
    "output.to_csv('submissionv15.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at racai/distilbert-base-romanian-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at racai/distilbert-base-romanian-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ]
  }
 ]
}
